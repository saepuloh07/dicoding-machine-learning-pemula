# -*- coding: utf-8 -*-
"""MLP_Muhamad_Saepuloh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-t2-fmewZyN_NSD0_Fjbr5pkk3Cj5_V_
"""

# import library tensorflow
import tensorflow as tf
import zipfile,os

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

print(tf.__version__)

# dowbload dataset
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /content/rockpaperscissors.zip

# ekstrak dataset
local_zip = '/content/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

class myCheckAccuracy(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.85):
      print("\nAkurasi di atas 85%, hentikan training!")
      self.model.stop_training = True

checkAccuracy = myCheckAccuracy()

# install lib untuk split folder
!pip install split_folders

# proses split folder
import splitfolders

splitfolders.ratio('/content/rockpaperscissors/rps-cv-images', '/content/rockpaperscissors/hasil_output', seed=1, ratio=(.6, .4))

# buat variable
base_dir = '/content/rockpaperscissors'
train_dir = os.path.join(base_dir, 'hasil_output/train')
valid_dir = os.path.join(base_dir, 'hasil_output/val')
rock_dir = os.path.join(base_dir, 'rock')
paper_dir = os.path.join(base_dir, 'paper')
scissors_dir = os.path.join(base_dir, 'scissors')

# check folder
os.listdir(train_dir)
os.listdir(valid_dir)

# buat direktori
train_paper_dir = os.path.join(train_dir, 'paper')
train_rock_dir = os.path.join(train_dir, 'rock')
train_scissors_dir = os.path.join(train_dir, 'scissors')

val_paper_dir = os.path.join(valid_dir, 'paper')
val_rock_dir = os.path.join(valid_dir, 'rock')
val_scissors_dir = os.path.join(valid_dir, 'scissors')

# dataset dibagi menjadi train set dan validation set 
train_roc_dir, val_roc_dir = train_test_split(os.listdir(rock_dir), test_size = 0.40)
train_pap_dir, val_pap_dir = train_test_split(os.listdir(paper_dir), test_size = 0.40)
train_sci_dir, val_sci_dir = train_test_split(os.listdir(scissors_dir), test_size = 0.40)

# generate image generator
train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest')

test_datagen = ImageDataGenerator(
    rescale = 1./225,
    rotation_range = 20,
    horizontal_flip = True,
    vertical_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest')

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150,150),
    batch_size= 32,
    class_mode='categorical'
)

valid_generator = test_datagen.flow_from_directory(
    valid_dir,
    target_size = (150,150),
    batch_size = 32,
    class_mode = 'categorical'
)

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(512, activation= 'relu'),
  tf.keras.layers.Dense(3, activation= 'softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=20,
    validation_data=valid_generator,
    validation_steps=5,
    verbose=2,
      callbacks=[checkAccuracy]
    )

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  if classes[0,0]!=0:
   print('paper')
  elif classes[0,1]!=0:
   print('rock')
  else:
   print('scissors')